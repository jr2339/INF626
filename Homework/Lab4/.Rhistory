xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
plot(exp(log_post_informative)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
# Prior parameters on unknown mean (\theta):
# Assume we know that the mean is "around 5"
mu_0 = 5.0
tau_0_sq = 9.0
tau_0 = sqrt(tau_0_sq)
# Known sigma_sq
sigma_sq = 2.0
sigma = sqrt(sigma_sq)
# True mean of the random variate Y
# This is what we need to estimate, but
# to simulate data, we have to assign it here
mu_true = 3.0
# Compare these two values of "n"
# "n" is equal to the number of data observations
n_compare = c(2, 75)
#Based on the # of observation in normal distribuation to generate data
data_generation <- function(num_observation){
return(rnorm(num_observation, mean=mu_true, sd=sigma))
}
# Create a sequence of values for theta
theta = seq(-15,15,length.out = 10000)
#The prior
log.prior = dnorm(theta,mu_0,tau_0,log = TRUE)
#Likelihood function
log.likelihood <-function(input_data, input_theta,input_sigma = sigma){
result = 0;
for(data in input_data){
result = result + dnorm(data,input_theta,input_sigma,log = TRUE)
}
return(result)
}
#Calculate the postrior
data.1 <- data_generation(n_compare[1])
data.2 <- data_generation(n_compare[2])
log.likelihood.1 <- log.likelihood(data.1,theta)
log.likelihood.2 <- log.likelihood(data.2,theta)
postrior.1 <-log.prior + log.likelihood.1
postrior.2 <-log.prior + log.likelihood.2
# Create a multi-panel plot with three panels across three rows, and 2 column:
par(mfrow = c(3, 2)) #c(n_rows,n_columns)
plot(exp(log.prior)~theta, type ='l', col = 'blue',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.prior)~theta, type ='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.likelihood.1)~theta, type='l', col='blue',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(log.likelihood.2)~theta, type='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.1)~theta, type='l',col='blue',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.2)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
theta = seq(0,1,length.out = 10000)
alph_1 = 2
alph_2 = 10
beta_1 = 2
beta_2 = 10
# Prior Distribution
prior_vague = dbeta(theta, alph_1, beta_1)
prior_informative = dbeta(theta, alph_2, beta_2)
#Now, we will calculate log-prior probability
log.prior_vague = dbeta(theta, alph_1, beta_1, log = TRUE)
log.prior_informative = dbeta(theta, alph_2, beta_2,log = TRUE)
#Define x and n
x = 7
n = 10
#For each value of θ sequence, calculate the log-likelihood of observing x = 7, given that parameter value
log.likelihood = dbinom(x,n,theta,log=TRUE)
#Postirior
log_post_vague = log.likelihood + log.prior_vague
log_post_informative = log.likelihood + log.prior_informative
# Create a multi-panel plot with three panels across three rows, and 2 column:
par(mfrow = c(3, 2)) #c(n_rows,n_columns)
plot(exp(log.prior_vague)~theta, type ='l', col = 'blue',
#xlim = c(0, 1), ylim = c(0, 5), #ylim are arbitrary here
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~alpha~", "~beta~")")
)
plot(exp(log.prior_informative)~theta, type ='l', col = 'red',
#xlim = c(0, 1), ylim = c(0, 20), #ylim are arbitrary here
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~alpha~", "~beta~")")
)
plot(exp(log.likelihood)~theta, type='l', col='blue',
xlab=expression(""~theta~""),
ylab=expression("P(X | "~theta~", n)"))
plot(exp(log.likelihood)~theta, type='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P(X | "~theta~", n)"))
plot(exp(log_post_vague)~theta, type='l',col='blue',
xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
plot(exp(log_post_informative)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
# Prior parameters on unknown mean (\theta):
# Assume we know that the mean is "around 5"
mu_0 = 5.0
tau_0_sq = 9.0
tau_0 = sqrt(tau_0_sq)
# Known sigma_sq
sigma_sq = 2.0
sigma = sqrt(sigma_sq)
# True mean of the random variate Y
# This is what we need to estimate, but
# to simulate data, we have to assign it here
mu_true = 3.0
# Compare these two values of "n"
# "n" is equal to the number of data observations
n_compare = c(2, 75)
#Based on the # of observation in normal distribuation to generate data
data_generation <- function(num_observation){
return(rnorm(num_observation, mean=mu_true, sd=sigma))
}
# Create a sequence of values for theta
theta = seq(-15,15,length.out = 10000)
#The prior
log.prior = dnorm(theta,mu_0,tau_0,log = TRUE)
#Likelihood function
log.likelihood <-function(input_data, input_theta,input_sigma = sigma){
result = 0;
for(data in input_data){
result = result + dnorm(data,input_theta,input_sigma,log = TRUE)
}
return(result)
}
#Calculate the postrior
data.1 <- data_generation(n_compare[1])
data.2 <- data_generation(n_compare[2])
log.likelihood.1 <- log.likelihood(data.1,theta)
log.likelihood.2 <- log.likelihood(data.2,theta)
postrior.1 <-log.prior + log.likelihood.1
postrior.2 <-log.prior + log.likelihood.2
# Create a multi-panel plot with three panels across three rows, and 2 column:
par(mfrow = c(3, 2)) #c(n_rows,n_columns)
plot(exp(log.prior)~theta, type ='l', col = 'blue',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.prior)~theta, type ='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.likelihood.1)~theta, type='l', col='blue',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(log.likelihood.2)~theta, type='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.1)~theta, type='l',col='blue',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.2)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
theta = seq(0,1,length.out = 10000)
alph_1 = 2
alph_2 = 10
beta_1 = 2
beta_2 = 10
# Prior Distribution
prior_vague = dbeta(theta, alph_1, beta_1)
prior_informative = dbeta(theta, alph_2, beta_2)
#Now, we will calculate log-prior probability
log.prior_vague = dbeta(theta, alph_1, beta_1, log = TRUE)
log.prior_informative = dbeta(theta, alph_2, beta_2,log = TRUE)
#Define x and n
x = 7
n = 10
#For each value of θ sequence, calculate the log-likelihood of observing x = 7, given that parameter value
log.likelihood = dbinom(x,n,theta,log=TRUE)
#Postirior
log_post_vague = log.likelihood + log.prior_vague
log_post_informative = log.likelihood + log.prior_informative
# Create a multi-panel plot with three panels across three rows, and 2 column:
par(mfrow = c(3, 2)) #c(n_rows,n_columns)
plot(exp(log.prior_vague)~theta, type ='l', col = 'blue',
#xlim = c(0, 1), ylim = c(0, 5), #ylim are arbitrary here
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~alpha~", "~beta~")")
)
plot(exp(log.prior_informative)~theta, type ='l', col = 'red',
#xlim = c(0, 1), ylim = c(0, 20), #ylim are arbitrary here
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~alpha~", "~beta~")")
)
plot(exp(log.likelihood)~theta, type='l', col='blue',
xlab=expression(""~theta~""),
ylab=expression("P(X | "~theta~", n)"))
plot(exp(log.likelihood)~theta, type='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P(X | "~theta~", n)"))
plot(exp(log_post_vague)~theta, type='l',col='blue',
xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
plot(exp(log_post_informative)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab = expression("P("~theta~"|"~x~","~n~")"))
# Prior parameters on unknown mean (\theta):
# Assume we know that the mean is "around 5"
mu_0 = 5.0
tau_0_sq = 9.0
tau_0 = sqrt(tau_0_sq)
# Known sigma_sq
sigma_sq = 2.0
sigma = sqrt(sigma_sq)
# True mean of the random variate Y
# This is what we need to estimate, but
# to simulate data, we have to assign it here
mu_true = 3.0
# Compare these two values of "n"
# "n" is equal to the number of data observations
n_compare = c(2, 75)
#Based on the # of observation in normal distribuation to generate data
data_generation <- function(num_observation){
return(rnorm(num_observation, mean=mu_true, sd=sigma))
}
# Create a sequence of values for theta
theta = seq(-15,15,length.out = 10000)
#The prior
log.prior = dnorm(theta,mu_0,tau_0,log = TRUE)
#Likelihood function
log.likelihood <-function(input_data, input_theta,input_sigma = sigma){
result = 0;
for(data in input_data){
result = result + dnorm(data,input_theta,input_sigma,log = TRUE)
}
return(result)
}
#Calculate the postrior
data.1 <- data_generation(n_compare[1])
data.2 <- data_generation(n_compare[2])
log.likelihood.1 <- log.likelihood(data.1,theta)
log.likelihood.2 <- log.likelihood(data.2,theta)
postrior.1 <-log.prior + log.likelihood.1
postrior.2 <-log.prior + log.likelihood.2
# Create a multi-panel plot with three panels across three rows, and 2 column:
par(mfrow = c(3, 2)) #c(n_rows,n_columns)
plot(exp(log.prior)~theta, type ='l', col = 'blue',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.prior)~theta, type ='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P("~theta~" | "~mu[0]~", "~tau[0]~"^2)")
)
plot(exp(log.likelihood.1)~theta, type='l', col='blue',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(log.likelihood.2)~theta, type='l', col = 'red',
xlab=expression(""~theta~""),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.1)~theta, type='l',col='blue',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
plot(exp(postrior.2)~theta, type='l',col = 'red',
xlab = expression(theta),
ylab=expression("P(y | "~theta~", "~sigma~"^2)")
)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
#-----------------------------------
#-----------------------------------
mu_true = 3
sd_fixed = 2
mu_prior = 5
sd_prior = 10
mu_prop = 5
sd_prop = sd_prior * 1.1
#-----------------------------------
#-----------------------------------
n_sample = 30
y_test = rnorm(n_sample, mu_true, sd_fixed)
#-----------------------------------
#-----------------------------------
n_iter = 10000
chosen_theta = NULL
for(i in 1:n_iter){
if(i == 1){
old_theta = rnorm(1, mu_prop, sd_prop)
}
new_theta = rnorm(1, mu_prop, sd_prop)
old_prop_adj = dnorm(old_theta, mu_prop, sd_prop, log = TRUE)
new_prop_adj = dnorm(new_theta, mu_prop, sd_prop, log = TRUE)
old_prior = dnorm(old_theta, mu_prior, sd_prior, log = TRUE)
new_prior = dnorm(new_theta, mu_prior, sd_prior, log = TRUE)
old_lik = sum(dnorm(y_test, old_theta, sd_fixed, log = TRUE))
new_lik = sum(dnorm(y_test, new_theta, sd_fixed, log = TRUE))
old_post = old_prior + old_lik
new_post = new_prior + new_lik
log_ratio = (new_post - new_prop_adj) - (old_post - old_prop_adj)
ratio = exp(log_ratio)
if(ratio > 1){
chosen_theta[i] = new_theta
}else{
rand = runif(1, min = 0, max = 1)
if(ratio >= rand){
chosen_theta[i] = new_theta
}else{
chosen_theta[i] = old_theta
}
}
old_theta = chosen_theta[i]
}
par(mfrow = c(1, 2))
# Plot the full trace:
plot(chosen_theta ~ c(1:n_iter), type = "l",
xlab = "Iteration", ylab = expression(theta~"|"~y))
# Discard the burn-in
# Plot the sample of the estimated posterior of \theta
n_burn = n_iter / 2
hist(chosen_theta[n_burn:n_iter], main = "",
xlab = expression(theta~"|"~y), ylab = "Frequency")
# Add the mean estimate
mu_est = mean(chosen_theta[n_burn:n_iter])
abline(v=mu_est, col = "blue", lwd = 2)
# Add the true mean
abline(v = mu_true, col = "black", lwd = 3, lty = 2)
par(mfrow = c(1,1))
knitr::opts_chunk$set(echo = TRUE)
#-----------------------------------
#-----------------------------------
#The mu and sd for the real distribution
mu_true = 3
sd_fixed = 2
#The mu and sd for the prior distribution
mu_prior = 5
sd_prior = 10
#The mu and sd for the proposal distribution
mu_prop = 5
sd_prop = sd_prior * 1.1
#-----------------------------------
#-----------------------------------
#Generate 30 observations from real distributation
n_sample = 30
y_test = rnorm(n_sample, mu_true, sd_fixed)
#-----------------------------------
#-----------------------------------
n_iter = 10000
chosen_theta = NULL
for(i in 1:n_iter){
# Initializing the old_theta
if(i == 1){
old_theta = rnorm(1, mu_prop, sd_prop)
}
# for each loop, it will generate a new theta
new_theta = rnorm(1, mu_prop, sd_prop)
#calculate the probability based on the old theta and new theta which follow proposal distribution
old_prop_adj = dnorm(old_theta, mu_prop, sd_prop, log = TRUE)
new_prop_adj = dnorm(new_theta, mu_prop, sd_prop, log = TRUE)
#calculate the probability based on the old theta and new theta which follow prior distribution
old_prior = dnorm(old_theta, mu_prior, sd_prior, log = TRUE)
new_prior = dnorm(new_theta, mu_prior, sd_prior, log = TRUE)
#Calculate the likelihood based on the old theta and new theta
old_lik = sum(dnorm(y_test, old_theta, sd_fixed, log = TRUE))
new_lik = sum(dnorm(y_test, new_theta, sd_fixed, log = TRUE))
# Calculate the posterior
old_post = old_prior + old_lik
new_post = new_prior + new_lik
# calculate log_ratio and ratio
log_ratio = (new_post - new_prop_adj) - (old_post - old_prop_adj)
ratio = exp(log_ratio)
# make a decision
if(ratio > 1){
chosen_theta[i] = new_theta
}else{
rand = runif(1, min = 0, max = 1)
if(ratio >= rand){
chosen_theta[i] = new_theta
}else{
chosen_theta[i] = old_theta
}
}
#assign the new value to the old_theta
old_theta = chosen_theta[i]
}
par(mfrow = c(1, 2))
# Plot the full trace:
plot(chosen_theta ~ c(1:n_iter), type = "l",
xlab = "Iteration", ylab = expression(theta~"|"~y))
# Discard the burn-in
# Plot the sample of the estimated posterior of \theta
n_burn = n_iter / 2
hist(chosen_theta[n_burn:n_iter], main = "",
xlab = expression(theta~"|"~y), ylab = "Frequency")
# Add the mean estimate
mu_est = mean(chosen_theta[n_burn:n_iter])
abline(v=mu_est, col = "blue", lwd = 2)
# Add the true mean
abline(v = mu_true, col = "black", lwd = 3, lty = 2)
par(mfrow = c(1,1))
#run multiple MCMC chains
result = NULL;
for(n in 1:10){
#-----------------------------------
#-----------------------------------
mu_true = 3
sd_fixed = 2
mu_prior = 5
sd_prior = 10
mu_prop = 5
sd_prop = sd_prior * 1.1
#-----------------------------------
#-----------------------------------
n_sample = 30
y_test = rnorm(n_sample, mu_true, sd_fixed)
#-----------------------------------
#-----------------------------------
n_iter = 10000
chosen_theta = NULL
for(i in 1:n_iter){
if(i == 1){
old_theta = rnorm(1, mu_prop, sd_prop)
}
new_theta = rnorm(1, mu_prop, sd_prop)
old_prop_adj = dnorm(old_theta, mu_prop, sd_prop, log = TRUE)
new_prop_adj = dnorm(new_theta, mu_prop, sd_prop, log = TRUE)
old_prior = dnorm(old_theta, mu_prior, sd_prior, log = TRUE)
new_prior = dnorm(new_theta, mu_prior, sd_prior, log = TRUE)
old_lik = sum(dnorm(y_test, old_theta, sd_fixed, log = TRUE))
new_lik = sum(dnorm(y_test, new_theta, sd_fixed, log = TRUE))
old_post = old_prior + old_lik
new_post = new_prior + new_lik
log_ratio = (new_post - new_prop_adj) - (old_post - old_prop_adj)
ratio = exp(log_ratio)
if(ratio > 1){
chosen_theta[i] = new_theta
}else{
rand = runif(1, min = 0, max = 1)
if(ratio >= rand){
chosen_theta[i] = new_theta
}else{
chosen_theta[i] = old_theta
}
}
old_theta = chosen_theta[i]
}
result[n] = chosen_theta
}
#run multiple MCMC chains
result = NULL;
for(n in 1:10){
#-----------------------------------
#-----------------------------------
mu_true = 3
sd_fixed = 2
mu_prior = 5
sd_prior = 10
mu_prop = 5
sd_prop = sd_prior * 1.1
#-----------------------------------
#-----------------------------------
n_sample = 30
y_test = rnorm(n_sample, mu_true, sd_fixed)
#-----------------------------------
#-----------------------------------
n_iter = 10000
chosen_theta = NULL
for(i in 1:n_iter){
if(i == 1){
old_theta = rnorm(1, mu_prop, sd_prop)
}
new_theta = rnorm(1, mu_prop, sd_prop)
old_prop_adj = dnorm(old_theta, mu_prop, sd_prop, log = TRUE)
new_prop_adj = dnorm(new_theta, mu_prop, sd_prop, log = TRUE)
old_prior = dnorm(old_theta, mu_prior, sd_prior, log = TRUE)
new_prior = dnorm(new_theta, mu_prior, sd_prior, log = TRUE)
old_lik = sum(dnorm(y_test, old_theta, sd_fixed, log = TRUE))
new_lik = sum(dnorm(y_test, new_theta, sd_fixed, log = TRUE))
old_post = old_prior + old_lik
new_post = new_prior + new_lik
log_ratio = (new_post - new_prop_adj) - (old_post - old_prop_adj)
ratio = exp(log_ratio)
if(ratio > 1){
chosen_theta[i] = new_theta
}else{
rand = runif(1, min = 0, max = 1)
if(ratio >= rand){
chosen_theta[i] = new_theta
}else{
chosen_theta[i] = old_theta
}
}
old_theta = chosen_theta[i]
result[n][i] = chosen_theta[i]
}
}
